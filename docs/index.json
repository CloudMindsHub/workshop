[
{
	"uri": "https://cloudmindshub.github.io/workshop/",
	"title": "Customizing Amazon Nova models",
	"tags": [],
	"description": "",
	"content": "Fine-tuning Amazon Nova models on AWS Bedrock Overview In recent years, Artificial Intelligence (AI) has emerged as a powerful tool, widely applied across various fields such as healthcare, education, business, and technology. However, for AI to truly understand and effectively solve a specific problem, we often need to \u0026ldquo;retrain\u0026rdquo; it using our own data. This process is called fine-tuning.\nSimply put, fine-tuning is a method that helps a pre-trained AI model become more suited to the specific needs and data of an individual or organization. Instead of building a model from scratch ‚Äî which can be time-consuming, labor-intensive, and expensive ‚Äî fine-tuning allows us to leverage existing capabilities and adjust them to make the AI work more efficiently in real-world scenarios. This is a crucial step in bringing AI into real applications that align closely with everyday usage needs.\nArchitecture The fine-tuning process of an AI model typically goes through the following steps: Main Content Introduction Prepare the dataset Fine-tune the model Evaluate the model Clean up resources "
},
{
	"uri": "https://cloudmindshub.github.io/workshop/1-introduce/",
	"title": "Introduce",
	"tags": [],
	"description": "",
	"content": "Concepts In this section, we introduce the key concepts and techniques used to customize the Amazon Nova model, including Fine-tuning, Distillation, and Continued Pre-training. Each method has its advantages and is suitable for different specific requirements.\nFine-tuning Concept:\nFine-tuning is the process of further training a pre-trained language model on a smaller, task-specific dataset. This helps the model better understand the specific context of the application domain.\nAdvantages:\nImproves performance on specialized tasks Requires less data compared to training from scratch Faster and cost-effective Disadvantages:\nProne to overfitting with limited data Can lead to catastrophic forgetting of general knowledge Real-world use cases:\nA customer support chatbot fine-tuned on internal company conversations for more accurate responses. A spam email classifier refined with organization-specific data for higher accuracy. A Medical NER application fine-tuned from a base model to process medical records. Distillation Concept:\nDistillation is a technique that transfers knowledge from a large, complex model (teacher) to a smaller, lightweight model (student), reducing size and improving inference speed.\nAdvantages:\nReduces model size and latency Easier deployment on resource-constrained devices (mobile, edge) Disadvantages:\nMay reduce performance compared to the original model Requires an additional training step Real-world use cases:\nCreating a lightweight version of a chatbot model for deployment on IoT devices in smart homes. Compressing a sentiment analysis model for integration into mobile customer support applications. Deploying a distilled plagiarism detection model for universities with limited computing resources. Continued Pre-training Concept:\nContinued pre-training involves further training a pre-trained language model on a large, unlabeled dataset specialized for a domain before fine-tuning.\nAdvantages:\nEnhances domain-specific knowledge absorption Improves generalization ability when fine-tuning Disadvantages:\nRequires significant computational resources Needs a large and domain-relevant dataset Real-world use cases:\nPre-training a model on millions of scientific articles before fine-tuning it for an academic information extraction system. Using data from tech forums to continue training a model before refining it for a technical assistant. Further training a model on corporate financial data to improve financial report analysis systems. Comparison of Model Customization Techniques Criteria Fine-tuning Distillation Continued Pre-training Input Data Labeled Labeled + Teacher Model Unlabeled Main Goal Customize model for a specific task Compress model, speed up inference Expand domain-specific knowledge Resource Requirement Medium Low High Deployment Feasibility Easy with existing models Suitable for low-resource devices Requires complex training pipeline Complexity Moderate Low to Medium High Overfitting Risk High if data is limited Low Low Key Advantage Strong task-specific adaptation Lightweight, fast, easy deployment Deeper domain learning, better generalization Disadvantages Potential loss of general knowledge Lower performance than original model Resource-intensive, requires large data Example Applications Enterprise chatbot, text classification Mobile apps, IoT, embedded systems Specialized information extraction, financial analysis Summary In this introduction, we have clarified three key methods for customizing the Amazon Nova model: Fine-tuning, Distillation, and Continued Pre-training. Each method has different strengths, weaknesses, and requirements, serving specific deployment goals:\nIf the goal is precise task-specific responses, Fine-tuning is the optimal choice. If the priority is deployment on low-resource devices, Distillation is the best solution. When deeper domain understanding is needed, Continued Pre-training is an effective approach. In the following sections, we will detail how to apply each technique in the Nova model training process, along with supporting tools and architectures.\n"
},
{
	"uri": "https://cloudmindshub.github.io/workshop/2-dataset/",
	"title": "Prepare dataset",
	"tags": [],
	"description": "",
	"content": "Dataset Overview This dataset is an extension of the Viet Document VAQ project, built from 64,765 pages of Vietnamese üáªüá≥ educational documents, including workbooks, thematic books, and lesson plans from reputable publishers such as the Ministry of Education and Training (MOET), C√°nh Di·ªÅu, Ch√¢n Tr·ªùi S√°ng T·∫°o, and K·∫øt N·ªëi Tri Th·ª©c. It covers all subjects from grades 1 to 12.\nEach page has been meticulously processed and annotated using advanced Visual Question Answering (VQA) techniques, resulting in a high-quality and information-rich dataset.\nThe dataset consists of 388,277 contextual question-answer pairs and detailed descriptions, automatically generated by Gemini 1.5 Flash ‚Äì Google‚Äôs leading AI model currently ranked #1 on the WildVision Arena leaderboard. This makes it an ideal resource for modern educational applications and academic research.\nSubjects included: Mathematics üìê, Literature üìö, English üá¨üáß, Physics ‚öõÔ∏è, Chemistry üß™, Biology üå±, History üìú, Geography üåç, Civics üè´, Informatics üíª, Technology üõ†Ô∏è, Music üéµ, Art üé®, Physical Education ‚öΩ, and more.\nDataset Processing Import required libraries import json import csv import pandas as pd import numpy as np Read parquet file into DataFrame df = pd.read_parquet(\u0026#39;train-00000-of-00034.parquet\u0026#39;, engine=\u0026#34;pyarrow\u0026#34;) df[\u0026#39;conversations\u0026#39;] = df[\u0026#39;conversations\u0026#39;].apply( lambda x: json.dumps(x.tolist(), ensure_ascii=False) if isinstance(x, np.ndarray) else json.dumps(x, ensure_ascii=False) ) Split dataset into train (80%), val (10%), and test (10%) from sklearn.model_selection import train_test_split # Split into training (80%) and val_test (20%) train_df, val_test_df = train_test_split(df, test_size=0.2) # Further split val_test into validation (10%) and test (10%) val_df, test_df = train_test_split(val_test_df, test_size=0.5) train_df.to_csv(\u0026#34;viet_vqa_train.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;) val_df.to_csv(\u0026#34;viet_vqa_val.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;) test_df.to_csv(\u0026#34;viet_vqa_test.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;) df_train = pd.read_csv(\u0026#39;viet_vqa_train.csv\u0026#39;) df_val = pd.read_csv(\u0026#39;viet_vqa_val.csv\u0026#39;) df_test = pd.read_csv(\u0026#39;viet_vqa_test.csv\u0026#39;) Format Data According to AWS Bedrock Format Sample AWS Bedrock format { \u0026#34;schemaVersion\u0026#34;: \u0026#34;bedrock-conversation-2024\u0026#34;, \u0026#34;system\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;You are an AI assistant specialized in Q\u0026amp;A based on Vietnamese images. You can analyze image content, recognize text (OCR), understand context, and answer questions based on extracted information. Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. Concise Responses: Provide clear, precise, and natural Vietnamese responses. Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. Professional \u0026amp; Objective: Respond factually based on the image, avoiding assumptions beyond the given data.\u0026#34; } ], \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;text\u0026#34;: \u0026#34;\u0026#34;}, { \u0026#34;image\u0026#34;: { \u0026#34;format\u0026#34;: \u0026#34;png\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;s3Location\u0026#34;: { \u0026#34;uri\u0026#34;: \u0026#34;s3://test-fineture-novalite/data-fineture/image_sample_1.jpg\u0026#34;, \u0026#34;bucketOwner\u0026#34;: \u0026#34;590******512\u0026#34; } } } } ] }, { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;text\u0026#34;: \u0026#34;\u0026#34;} ] } ] } Function to format data def create_jsonl_item(row): try: conversations = row.get(\u0026#34;conversations\u0026#34;) message_id = row.get(\u0026#34;id\u0026#34;) if isinstance(conversations, str): conversations = json.loads(conversations) if not isinstance(conversations, list): raise ValueError(\u0026#34;Invalid JSON format in conversations column\u0026#34;) if len(conversations) \u0026gt; 0 and conversations[0][\u0026#34;role\u0026#34;] == \u0026#34;user\u0026#34;: original_text = conversations[0][\u0026#34;content\u0026#34;] image_info = { \u0026#34;image\u0026#34;: { \u0026#34;format\u0026#34;: \u0026#34;png\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;s3Location\u0026#34;: { \u0026#34;uri\u0026#34;: f\u0026#34;s3://data-vqa-fine-tune-nova/train/image_{message_id}.png\u0026#34;, \u0026#34;bucketOwner\u0026#34;: \u0026#34;536697245883\u0026#34; } } } } conversations[0][\u0026#34;content\u0026#34;] = [ {\u0026#34;text\u0026#34;: original_text}, image_info ] return { \u0026#34;schemaVersion\u0026#34;: \u0026#34;bedrock-conversation-2024\u0026#34;, \u0026#34;system\u0026#34;: [ { \u0026#34;text\u0026#34;: ( \u0026#34;You are an AI assistant specialized in Q\u0026amp;A based on Vietnamese images. \u0026#34; \u0026#34;You can analyze image content, recognize text (OCR), understand context, \u0026#34; \u0026#34;and answer questions based on extracted information. \u0026#34; \u0026#34;Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. \u0026#34; \u0026#34;Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. \u0026#34; \u0026#34;Concise Responses: Provide clear, precise, and natural Vietnamese responses. \u0026#34; \u0026#34;Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. \u0026#34; \u0026#34;Professional \u0026amp; Objective: Respond factually based on the image, avoiding assumptions beyond the given data.\u0026#34; ) } ], \u0026#34;messages\u0026#34;: conversations } except Exception as e: print(f\u0026#34;Error processing conversations: {e}, row ID: {row[\u0026#39;id\u0026#39;]}, {conversations}\u0026#34;) return None Apply function to entire DataFrame jsonl_data = df_sample.apply(create_jsonl_item, axis=1).tolist() Save to JSONL file jsonl_data = [item for item in jsonl_data if item is not None]\rwith open(\u0026#34;data_finetune_100.jsonl\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f:\rfor item in jsonl_data:\rjson.dump(item, f, ensure_ascii=False)\rf.write(\u0026#34;\\n\u0026#34;) Follow the same process to generate JSONL files for the validation and test datasets.\n"
},
{
	"uri": "https://cloudmindshub.github.io/workshop/3-train/",
	"title": "Fine-tuning",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/4-evaluation/",
	"title": "ƒê√°nh gi√° m√¥ h√¨nh",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/5-clean/",
	"title": "D·ªçn t√†i nguy√™n",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]