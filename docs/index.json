[
{
	"uri": "https://cloudmindshub.github.io/workshop/",
	"title": "Customizing Amazon Nova models",
	"tags": [],
	"description": "",
	"content": "Fine-tuning Amazon Nova models on AWS Bedrock Overview In recent years, Artificial Intelligence (AI) has emerged as a powerful tool, widely applied across various fields such as healthcare, education, business, and technology. However, for AI to truly understand and effectively solve a specific problem, we often need to \u0026ldquo;retrain\u0026rdquo; it using our own data. This process is called fine-tuning.\nSimply put, fine-tuning is a method that helps a pre-trained AI model become more suited to the specific needs and data of an individual or organization. Instead of building a model from scratch — which can be time-consuming, labor-intensive, and expensive — fine-tuning allows us to leverage existing capabilities and adjust them to make the AI work more efficiently in real-world scenarios. This is a crucial step in bringing AI into real applications that align closely with everyday usage needs.\nArchitecture The fine-tuning process of an AI model typically goes through the following steps:\nMain Content Introduction Prepare the dataset Fine-tune the model Evaluate the model Clean up resources "
},
{
	"uri": "https://cloudmindshub.github.io/workshop/2-dataset/2.1-handle/",
	"title": "Handle dataset",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/1-introduce/",
	"title": "Introduce",
	"tags": [],
	"description": "",
	"content": "In this section, we will explore three main methods for personalizing and optimizing the Amazon Nova language model:\nFine-tuning: Retraining on a labeled dataset tailored for a specific task. Distillation: Transferring knowledge from a large model (teacher) to a smaller model (student). Continued Pre-training: Further training the model on a large-scale, unlabeled dataset focused on a specialized domain before fine-tuning. Each method has distinct characteristics and is suitable for different real-world application requirements.\nAmazon Bedrock To efficiently and quickly implement customization methods such as Fine-tuning, Distillation, and Continued Pre-training, Amazon Bedrock is the ideal service.\nAmazon Bedrock is a powerful platform that enables you to build and deploy generative AI applications without managing complex infrastructure. With Bedrock, you can easily access leading large language models (LLMs) from providers like AI21 Labs, Anthropic, Cohere, Meta, Stability AI, and Amazon, while performing fine-tuning directly on your proprietary data.\nThrough Bedrock, model customization becomes remarkably straightforward:\nNo need to build expensive GPU infrastructure. Supports model customization with internal data in just a few configuration steps. Ensures high security, as training and inference data are protected on AWS. Easily integrates into existing applications via simple and robust APIs. As a result, Amazon Bedrock reduces development time, lowers operational costs, and increases flexibility when deploying specialized AI solutions tailored to specific business needs.\nFine-tuning Concept: Fine-tuning is the process of retraining a pre-trained language model on a specialized, labeled dataset. This process adjusts the model’s parameters to optimize performance for a specific task or domain, enabling the model to adapt to the context and nuances of the application domain.\nAdvantages:\nSignificantly improves performance on specialized tasks compared to the original model. Saves computational resources as it does not require training from scratch. Requires less data than pre-training (typically thousands to hundreds of thousands of samples). Shorter training time, ranging from a few hours to a few days, depending on model scale. Flexible for adapting to various tasks. Disadvantages:\nHigh risk of overfitting if the dataset is too small or lacks diversity. Catastrophic forgetting: May lose general knowledge from the original model. Imbalanced performance across different tasks. Real-world Use Cases:\nCustomer service chatbots: Fine-tune to understand company policies, products, and communication style, improving accuracy in responses aligned with internal processes. Specialized text classification systems: For example, classifying organization-specific spam emails or categorizing legal documents into specific categories. Healthcare: Fine-tune the model for Medical Named Entity Recognition (NER) in patient records, enhancing the extraction of information about diseases, medications, and diagnoses. Distillation Concept: Distillation (model distillation) is a technique for transferring knowledge from a large, complex model (teacher model) to a smaller, lighter model (student model). This method uses the probability distribution outputs from the teacher model to train the student model, enabling the smaller model to mimic the capabilities of the larger one.\nAdvantages:\nSignificantly reduces model size (by 50-90% of parameters). Increases inference speed and reduces latency. Lowers memory and energy requirements during deployment. Preserves much of the original model’s capabilities in a more compact architecture. Enables deployment on resource-constrained devices like smartphones or IoT devices. Disadvantages:\nReduced performance compared to the original teacher model, especially on complex tasks. Requires a more complex training process, needing optimization of multiple hyperparameters. Requires balancing size and performance for optimal results. Depends on the quality of the teacher model and transfer data. Real-world Use Cases:\nVirtual assistants on mobile devices: Create a lightweight version of a chat model to run directly on smartphones, reducing latency and enhancing privacy. Smart home systems: Deploy compact models on IoT devices for natural language processing and decision-making without cloud connectivity. Continued Pre-training Concept: Continued Pre-training is the process of further training a pre-trained large language model on a new, unlabeled dataset, typically specialized for a specific domain. This method helps the model absorb additional domain-specific knowledge before fine-tuning for specific tasks.\nAdvantages:\nExpands the model’s domain-specific knowledge. Significantly improves performance when combined with subsequent fine-tuning. Enhances generalization when processing new data. Reduces catastrophic forgetting compared to fine-tuning alone. Highly effective for specialized domains like healthcare, law, or finance. Disadvantages:\nRequires significant computational resources, often needing powerful GPUs/TPUs and extended time. Demands large, high-quality datasets from the target domain. Complex training process, difficult to optimize and monitor. Risk of bias in training data if not carefully filtered. High costs for both data and computational resources. Real-world Use Cases:\nHealthcare: Continue pre-training on medical datasets (e.g., millions of PUBMED articles, patient records) before fine-tuning for diagnosis or treatment consultation. Finance: Train on financial reports, economic news, and market data before fine-tuning for investment analysis or market forecasting. Legal: Pre-train on legal texts, case law, and documents before fine-tuning for contract drafting or analysis systems. Scientific research: Continue training on a corpus of scientific papers in a specific field before fine-tuning for information extraction or research summarization. Comparison of Model Customization Techniques Criteria Fine-tuning Distillation Continued Pre-training Input Data Type Labeled, task-specific Labeled and teacher model predictions Unlabeled, domain-specific Data Volume Required Thousands to hundreds of thousands of samples Moderate, task-dependent Large (millions of texts) Training Time Hours to days Moderate Days to weeks Primary Goal Optimize for specific tasks Reduce size, speed up inference Add domain-specific knowledge Computational Resource Needs Moderate Low to moderate Very high Implementation Complexity Simple Moderate Complex Scalability Limited to trained tasks Good for large-scale deployment Flexible for subsequent tasks Overfitting Risk High with limited data Low to moderate Low Impact on Original Knowledge May lose general knowledge Preserves much of it Expands and supplements Operational Cost Low to moderate Very low High Suitable For Specific tasks with labeled data Resource-constrained environments Specialized, complex domains Evaluation Method Task-specific metrics Comparison with teacher model Perplexity and downstream downstream evaluation Each method for customizing the Amazon Nova model plays a unique role in adapting large language models to real-world applications:\nFine-tuning: Ideal when precise responses are needed for a specific task, especially with high-quality labeled data. Distillation: Efficient for deploying models on resource-constrained devices, prioritizing response speed and cost-efficiency. Continued Pre-training: Suitable for achieving deep understanding of a specific domain, particularly in fields like healthcare, law, or finance. The choice and combination of these methods depend on specific performance requirements, available resources, and application characteristics.\nSince Distillation on AWS Bedrock is in preview, and Continued Pre-training is complex and costly, Fine-tuning is a more popular choice for real-world business use cases. After testing the Nova Lite model, we found that it underperforms on Vietnamese image-based question-answering tasks. Therefore, within the scope of this workshop, we will fine-tune the model using a Vietnamese image-based question-answering dataset.\n"
},
{
	"uri": "https://cloudmindshub.github.io/workshop/2-dataset/",
	"title": "Prepare dataset",
	"tags": [],
	"description": "",
	"content": "Dataset Overview This dataset is an extension of the Viet Document VAQ project, built from 64,765 pages of Vietnamese 🇻🇳 educational documents, including workbooks, thematic books, and lesson plans from reputable publishers such as the Ministry of Education and Training (MOET), Cánh Diều, Chân Trời Sáng Tạo, and Kết Nối Tri Thức. It covers all subjects from grades 1 to 12.\nEach page has been meticulously processed and annotated using advanced Visual Question Answering (VQA) techniques, resulting in a high-quality and information-rich dataset.\nThe dataset consists of 388,277 contextual question-answer pairs and detailed descriptions, automatically generated by Gemini 1.5 Flash – Google’s leading AI model currently ranked #1 on the WildVision Arena leaderboard. This makes it an ideal resource for modern educational applications and academic research.\nSubjects included: Mathematics 📐, Literature 📚, English 🇬🇧, Physics ⚛️, Chemistry 🧪, Biology 🌱, History 📜, Geography 🌍, Civics 🏫, Informatics 💻, Technology 🛠️, Music 🎵, Art 🎨, Physical Education ⚽, and more.\nDataset Processing Import required libraries import json import csv import pandas as pd import numpy as np Read parquet file into DataFrame df = pd.read_parquet(\u0026#39;train-00000-of-00034.parquet\u0026#39;, engine=\u0026#34;pyarrow\u0026#34;) df[\u0026#39;conversations\u0026#39;] = df[\u0026#39;conversations\u0026#39;].apply( lambda x: json.dumps(x.tolist(), ensure_ascii=False) if isinstance(x, np.ndarray) else json.dumps(x, ensure_ascii=False) ) Split dataset into train (80%), val (10%), and test (10%) from sklearn.model_selection import train_test_split # Split into training (80%) and val_test (20%) train_df, val_test_df = train_test_split(df, test_size=0.2) # Further split val_test into validation (10%) and test (10%) val_df, test_df = train_test_split(val_test_df, test_size=0.5) train_df.to_csv(\u0026#34;viet_vqa_train.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;) val_df.to_csv(\u0026#34;viet_vqa_val.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;) test_df.to_csv(\u0026#34;viet_vqa_test.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;) df_train = pd.read_csv(\u0026#39;viet_vqa_train.csv\u0026#39;) df_val = pd.read_csv(\u0026#39;viet_vqa_val.csv\u0026#39;) df_test = pd.read_csv(\u0026#39;viet_vqa_test.csv\u0026#39;) Format Data According to AWS Bedrock Format Sample AWS Bedrock format { \u0026#34;schemaVersion\u0026#34;: \u0026#34;bedrock-conversation-2024\u0026#34;, \u0026#34;system\u0026#34;: [ { \u0026#34;text\u0026#34;: \u0026#34;You are an AI assistant specialized in Q\u0026amp;A based on Vietnamese images. You can analyze image content, recognize text (OCR), understand context, and answer questions based on extracted information. Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. Concise Responses: Provide clear, precise, and natural Vietnamese responses. Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. Professional \u0026amp; Objective: Respond factually based on the image, avoiding assumptions beyond the given data.\u0026#34; } ], \u0026#34;messages\u0026#34;: [ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;text\u0026#34;: \u0026#34;\u0026#34;}, { \u0026#34;image\u0026#34;: { \u0026#34;format\u0026#34;: \u0026#34;png\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;s3Location\u0026#34;: { \u0026#34;uri\u0026#34;: \u0026#34;s3://test-fineture-novalite/data-fineture/image_sample_1.jpg\u0026#34;, \u0026#34;bucketOwner\u0026#34;: \u0026#34;590******512\u0026#34; } } } } ] }, { \u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;text\u0026#34;: \u0026#34;\u0026#34;} ] } ] } Function to format data def create_jsonl_item(row): try: conversations = row.get(\u0026#34;conversations\u0026#34;) message_id = row.get(\u0026#34;id\u0026#34;) if isinstance(conversations, str): conversations = json.loads(conversations) if not isinstance(conversations, list): raise ValueError(\u0026#34;Invalid JSON format in conversations column\u0026#34;) if len(conversations) \u0026gt; 0 and conversations[0][\u0026#34;role\u0026#34;] == \u0026#34;user\u0026#34;: original_text = conversations[0][\u0026#34;content\u0026#34;] image_info = { \u0026#34;image\u0026#34;: { \u0026#34;format\u0026#34;: \u0026#34;png\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;s3Location\u0026#34;: { \u0026#34;uri\u0026#34;: f\u0026#34;s3://data-vqa-fine-tune-nova/train/image_{message_id}.png\u0026#34;, \u0026#34;bucketOwner\u0026#34;: \u0026#34;536697245883\u0026#34; } } } } conversations[0][\u0026#34;content\u0026#34;] = [ {\u0026#34;text\u0026#34;: original_text}, image_info ] return { \u0026#34;schemaVersion\u0026#34;: \u0026#34;bedrock-conversation-2024\u0026#34;, \u0026#34;system\u0026#34;: [ { \u0026#34;text\u0026#34;: ( \u0026#34;You are an AI assistant specialized in Q\u0026amp;A based on Vietnamese images. \u0026#34; \u0026#34;You can analyze image content, recognize text (OCR), understand context, \u0026#34; \u0026#34;and answer questions based on extracted information. \u0026#34; \u0026#34;Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. \u0026#34; \u0026#34;Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. \u0026#34; \u0026#34;Concise Responses: Provide clear, precise, and natural Vietnamese responses. \u0026#34; \u0026#34;Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. \u0026#34; \u0026#34;Professional \u0026amp; Objective: Respond factually based on the image, avoiding assumptions beyond the given data.\u0026#34; ) } ], \u0026#34;messages\u0026#34;: conversations } except Exception as e: print(f\u0026#34;Error processing conversations: {e}, row ID: {row[\u0026#39;id\u0026#39;]}, {conversations}\u0026#34;) return None Apply function to entire DataFrame jsonl_data = df_sample.apply(create_jsonl_item, axis=1).tolist() Save to JSONL file jsonl_data = [item for item in jsonl_data if item is not None]\rwith open(\u0026#34;data_finetune_100.jsonl\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f:\rfor item in jsonl_data:\rjson.dump(item, f, ensure_ascii=False)\rf.write(\u0026#34;\\n\u0026#34;) Follow the same process to generate JSONL files for the validation and test datasets.\n"
},
{
	"uri": "https://cloudmindshub.github.io/workshop/2-dataset/2.2-upload/",
	"title": "Upload dataset",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/3-train/",
	"title": "Fine-tuning",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/4-evaluation/",
	"title": "Đánh giá mô hình",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/5-clean/",
	"title": "Dọn tài nguyên",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]