[
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/",
	"title": "Customizing Amazon Nova models",
	"tags": [],
	"description": "",
	"content": "Fine-tuning Amazon Nova models trên AWS Bedrock Tổng quan Trong những năm gần đây, trí tuệ nhân tạo (AI) đã trở thành một công cụ mạnh mẽ, được ứng dụng rộng rãi trong nhiều lĩnh vực như y tế, giáo dục, kinh doanh, và công nghệ. Tuy nhiên, để AI thật sự hiểu và giải quyết tốt một vấn đề cụ thể, chúng ta thường cần \u0026ldquo;dạy lại\u0026rdquo; nó bằng dữ liệu riêng của mình. Việc này gọi là fine-tuning, hay còn gọi là tinh chỉnh mô hình. Nói đơn giản, đây là cách giúp một mô hình AI đã được huấn luyện sẵn trở nên phù hợp hơn với nhu cầu và dữ liệu của từng cá nhân hoặc tổ chức. Thay vì phải xây dựng một mô hình từ đầu – vừa tốn thời gian, công sức và chi phí – thì fine-tuning giúp ta tận dụng sức mạnh có sẵn, rồi điều chỉnh lại để AI hoạt động hiệu quả hơn trong bối cảnh thực tế của mình. Đây là một bước quan trọng giúp đưa AI vào ứng dụng thật, sát với nhu cầu sử dụng hàng ngày.\nKiến trúc Quá trình fine-tuning một mô hình AI thường trải qua các bước sau:\nNội dung chính Giới thiệu Chuẩn bị dữ liệu Huấn luyện tinh chỉnh mô hình Đánh giá mô hình Clean up resources "
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Trong phần này, chúng ta sẽ cùng tìm hiểu ba phương pháp chính để cá nhân hóa và tối ưu hóa mô hình ngôn ngữ Amazon Nova:\nFine‑tuning: Huấn luyện lại trên tập dữ liệu có nhãn chuyên biệt cho một nhiệm vụ cụ thể.\nDistillation: Chưng cất kiến thức từ mô hình lớn (teacher) sang mô hình nhỏ (student).\nContinued Pre‑training: Tiếp tục huấn luyện mô hình trên tập dữ liệu không nhãn có quy mô lớn, tập trung vào một lĩnh vực chuyên ngành trước khi fine‑tuning.\nMỗi phương pháp đều có đặc điểm riêng biệt và phù hợp với các yêu cầu ứng dụng khác nhau trong thực tiễn.\nAmazon Bedrock Để thực hiện các phương pháp tùy chỉnh như Fine-tuning, Distillation, và Continued Pre-training một cách nhanh chóng và hiệu quả, Amazon Bedrock chính là dịch vụ lý tưởng.\nAmazon Bedrock là nền tảng mạnh mẽ cho phép bạn xây dựng và triển khai các ứng dụng AI tạo sinh (generative AI) mà không cần phải quản lý cơ sở hạ tầng phức tạp. Với Bedrock, bạn có thể dễ dàng truy cập vào nhiều mô hình ngôn ngữ lớn (LLMs) hàng đầu từ các nhà cung cấp nổi tiếng như AI21 Labs, Anthropic, Cohere, Meta, Stability AI, và Amazon, đồng thời thực hiện fine-tuning trực tiếp trên dữ liệu riêng của mình.\nThông qua Bedrock, việc cá nhân hóa mô hình trở nên cực kỳ đơn giản:\nKhông cần tự xây dựng hạ tầng GPU tốn kém. Hỗ trợ tùy chỉnh mô hình bằng dữ liệu nội bộ chỉ với vài bước cấu hình. Đảm bảo tính bảo mật cao, khi dữ liệu huấn luyện và dữ liệu inference đều được bảo vệ trên AWS. Dễ dàng tích hợp vào các ứng dụng hiện có thông qua API đơn giản và mạnh mẽ. Nhờ đó, Amazon Bedrock giúp rút ngắn thời gian phát triển, giảm chi phí vận hành và tăng tính linh hoạt khi triển khai các giải pháp AI chuyên biệt theo nhu cầu thực tế của từng doanh nghiệp.\nFine-tuning Khái niệm: Fine-tuning là quá trình huấn luyện lại một mô hình ngôn ngữ đã được pre-trained trên một tập dữ liệu chuyên biệt có nhãn. Quá trình này điều chỉnh các tham số của mô hình để tối ưu hóa hiệu suất cho một tác vụ hoặc miền cụ thể, giúp mô hình thích nghi với ngữ cảnh và đặc thù của lĩnh vực ứng dụng.\nƯu điểm:\nCải thiện hiệu suất đáng kể trên các tác vụ chuyên biệt so với mô hình gốc Tiết kiệm tài nguyên tính toán vì không cần huấn luyện lại từ đầu Yêu cầu ít dữ liệu hơn so với pre-training (thường chỉ vài nghìn đến vài trăm nghìn mẫu) Thời gian huấn luyện ngắn hơn, từ vài giờ đến vài ngày tùy quy mô mô hình Linh hoạt trong việc điều chỉnh cho nhiều tác vụ khác nhau Nhược điểm:\nNguy cơ overfitting cao nếu tập dữ liệu quá nhỏ hoặc thiếu đa dạng Catastrophic forgetting: có thể làm mất đi kiến thức tổng quát của mô hình gốc Mất cân bằng trong hiệu suất giữa các tác vụ khác nhau Use case thực tế:\nChatbot chăm sóc khách hàng: Fine-tune để hiểu chính sách, sản phẩm và phong cách giao tiếp của doanh nghiệp, tăng độ chính xác trong trả lời theo quy trình nội bộ. Hệ thống phân loại văn bản chuyên ngành: Như phân loại email spam theo đặc thù của tổ chức, hoặc phân loại tài liệu luật pháp theo các danh mục cụ thể. Y tế: Fine-tune mô hình để nhận dạng thực thể y tế (Medical NER) trong hồ sơ bệnh án, giúp trích xuất thông tin bệnh lý, thuốc và chẩn đoán chính xác hơn. Distillation Khái niệm: Distillation (chưng cất mô hình) là kỹ thuật chuyển giao tri thức từ một mô hình lớn, phức tạp (teacher model) sang một mô hình nhỏ, nhẹ hơn (student model). Phương pháp này sử dụng output phân phối xác suất từ mô hình teacher để huấn luyện mô hình student, giúp mô hình nhỏ hơn có thể bắt chước khả năng của mô hình lớn.\nƯu điểm:\nGiảm đáng kể kích thước mô hình (có thể giảm 50-90% tham số) Tăng tốc độ suy luận (inference) và giảm độ trễ (latency) Giảm yêu cầu bộ nhớ và năng lượng khi triển khai Bảo tồn phần lớn khả năng của mô hình gốc trong một kiến trúc nhỏ gọn hơn Cho phép triển khai trên thiết bị có tài nguyên hạn chế như điện thoại, thiết bị IoT Nhược điểm:\nGiảm hiệu suất so với mô hình teacher gốc, đặc biệt trên các tác vụ phức tạp Yêu cầu quy trình huấn luyện phức tạp hơn, cần tối ưu nhiều hyperparameter Cần cân bằng giữa kích thước và hiệu suất để đạt kết quả tối ưu Phụ thuộc vào chất lượng của mô hình teacher và dữ liệu chuyển giao Use case thực tế:\nTrợ lý ảo trên thiết bị di động: Tạo phiên bản nhẹ của mô hình chat để chạy trực tiếp trên smartphone, giảm độ trễ và bảo vệ quyền riêng tư. Hệ thống nhà thông minh: Triển khai mô hình nhỏ gọn trên các thiết bị IoT để xử lý ngôn ngữ tự nhiên và ra quyết định mà không cần kết nối cloud. Continued Pre-training Khái niệm: Continued Pre-training (tiếp tục tiền huấn luyện) là quá trình huấn luyện tiếp một mô hình ngôn ngữ lớn đã được pre-trained trên một tập dữ liệu mới, không có nhãn, thường chuyên biệt cho một lĩnh vực. Phương pháp này giúp mô hình hấp thụ thêm kiến thức chuyên ngành trước khi thực hiện fine-tuning cho các tác vụ cụ thể.\nƯu điểm:\nMở rộng kiến thức chuyên ngành của mô hình về lĩnh vực cụ thể Cải thiện đáng kể hiệu suất khi kết hợp với fine-tuning sau đó Tăng khả năng tổng quát hóa (generalization) khi xử lý dữ liệu mới Giảm thiểu vấn đề catastrophic forgetting so với chỉ fine-tuning Hiệu quả đặc biệt cho các lĩnh vực chuyên sâu như y tế, luật, tài chính Nhược điểm:\nĐòi hỏi tài nguyên tính toán lớn, thường cần GPU/TPU mạnh và thời gian dài Yêu cầu tập dữ liệu lớn và chất lượng từ lĩnh vực mục tiêu Quy trình huấn luyện phức tạp, khó tối ưu hóa và theo dõi Có nguy cơ bias từ dữ liệu huấn luyện nếu không được lọc kỹ Chi phí cao cho cả dữ liệu và tài nguyên tính toán Use case thực tế:\nY tế: Tiếp tục pre-train mô hình trên kho dữ liệu y khoa (hàng triệu bài báo PUBMED, hồ sơ bệnh án) trước khi fine-tune cho chẩn đoán, tư vấn điều trị. Tài chính: Huấn luyện trên báo cáo tài chính, tin tức kinh tế và dữ liệu thị trường trước khi fine-tune cho phân tích đầu tư, dự báo thị trường. Pháp lý: Pre-train liên tục trên văn bản luật, án lệ và tài liệu pháp lý trước khi fine-tune cho hệ thống hỗ trợ soạn thảo, phân tích hợp đồng. Nghiên cứu khoa học: Tiếp tục huấn luyện trên corpus bài báo khoa học ngành cụ thể trước khi fine-tune cho hệ thống trích xuất thông tin, tổng hợp nghiên cứu. So sánh các kỹ thuật tùy chỉnh mô hình Tiêu chí Fine-tuning Distillation Continued Pre-training Loại dữ liệu đầu vào Có nhãn, theo tác vụ Có nhãn và dự đoán từ mô hình teacher Không nhãn, theo miền/lĩnh vực Khối lượng dữ liệu cần thiết Từ vài nghìn đến vài trăm nghìn mẫu Vừa phải, phụ thuộc vào tác vụ Lớn (hàng triệu văn bản) Thời gian huấn luyện Vài giờ đến vài ngày Trung bình Vài ngày đến vài tuần Mục tiêu chính Tối ưu hóa cho tác vụ cụ thể Giảm kích thước, tăng tốc suy luận Bổ sung kiến thức chuyên ngành Yêu cầu tài nguyên tính toán Trung bình Thấp đến trung bình Rất cao Độ phức tạp triển khai Đơn giản Trung bình Phức tạp Khả năng mở rộng Giới hạn ở tác vụ được huấn luyện Tốt cho triển khai quy mô lớn Linh hoạt cho nhiều tác vụ sau đó Nguy cơ overfitting Cao nếu ít dữ liệu Thấp đến trung bình Thấp Ảnh hưởng đến kiến thức ban đầu Có thể làm mất kiến thức tổng quát Duy trì được phần lớn Mở rộng và bổ sung Chi phí vận hành Thấp đến trung bình Rất thấp Cao Thích hợp cho Tác vụ cụ thể, dữ liệu có nhãn sẵn có Môi trường giới hạn tài nguyên Các lĩnh vực đặc thù, phức tạp Phương pháp đánh giá Metrics cụ thể của tác vụ So sánh với mô hình teacher Perplexity và đánh giá downstream Mỗi phương pháp tùy chỉnh mô hình Amazon Nova đều có vai trò riêng trong việc thích nghi mô hình ngôn ngữ lớn vào các ứng dụng thực tế:\nFine-tuning: Lựa chọn tối ưu khi cần mô hình phản hồi chính xác cho một tác vụ cụ thể, đặc biệt khi có sẵn dữ liệu có nhãn chất lượng. Distillation: Giải pháp hiệu quả khi cần triển khai mô hình trên các thiết bị có tài nguyên hạn chế, ưu tiên tốc độ phản hồi và hiệu quả chi phí. Continued Pre-training: Hướng đi phù hợp khi cần mô hình thấu hiểu sâu sắc về một lĩnh vực chuyên môn cụ thể, đặc biệt trong các ngành như y tế, luật pháp hay tài chính. Việc lựa chọn và kết hợp các phương pháp này cần căn cứ vào yêu cầu cụ thể về hiệu suất, tài nguyên sẵn có và đặc thù ứng dụng.\nVì Distillation trên AWS Bedrock đang ở tình trạng preview, Continued Pre-training thì quá phức tạp và tốn chi phí cao, các bài toán thực tế ở các doanh nghiệp, Fine-tuning là một sự lụa chọn phổ biến hơn. Sau khi đã sử dụng và đánh giá thử mô hình Nova Lite, chúng tôi nhận ra Nova Lite chưa hoạt động tốt trên bài toán hỏi đáp dựa trên hình ảnh tiếng việt. Do đó, trong phạm vi workshop này, chúng tôi sẽ fine-tuning lại dựa trên bộ dữ liệu hỏi đáp trên hình ảnh tiếng việt.\n"
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-dataset/2.1-handle/",
	"title": "Xử lý dữ liệu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-dataset/",
	"title": "Chuẩn bị dataset",
	"tags": [],
	"description": "",
	"content": "Tổng quan về bộ dữ liệu Bộ dữ liệu này là phần mở rộng của dự án Viet-Doc VAQ, được xây dựng từ 64.765 trang tài liệu giáo dục tiếng Việt 🇻🇳, bao gồm: sách bài tập, sách chuyên đề, giáo án từ các nhà xuất bản chính thống như Bộ Giáo dục \u0026amp; Đào tạo, Cánh Diều, Chân Trời Sáng Tạo, Kết Nối Tri Thức,\u0026hellip; phủ rộng tất cả các môn học từ lớp 1 đến lớp 12.\nMỗi trang tài liệu đã được xử lý và chú thích kỹ lưỡng bằng các kỹ thuật Visual Question Answering (VQA), tạo nên một bộ dữ liệu có chất lượng cao và giàu thông tin.\nBộ dữ liệu bao gồm 388.277 cặp mô tả chi tiết và câu hỏi - trả lời theo ngữ cảnh, được tự động tạo ra bởi Gemini 1.5 Flash – mô hình AI hàng đầu của Google, đang dẫn đầu bảng xếp hạng WildVision Arena. Nhờ đó, đây là nguồn tài nguyên lý tưởng cho các mục tiêu nghiên cứu và ứng dụng giáo dục hiện đại.\nCác môn học bao gồm: Toán học 📐, Ngữ văn 📚, Tiếng Anh 🇬🇧, Vật lý ⚛️, Hóa học 🧪, Sinh học 🌱, Lịch sử 📜, Địa lý 🌍, Giáo dục công dân 🏫, Tin học 💻, Công nghệ 🛠️, Âm nhạc 🎵, Mỹ thuật 🎨, Thể dục ⚽,\u0026hellip;\nVì chi phí có giới hạn, chỉ để thử nghiệm việc fine-tuning mô hình trên AWS Bedrock, trong workshop này chỉ dùng 100 mẫu dữ liệu để huấn luyện (số lượng mẫu tối thiểu theo yêu cầu của Bedrock ).\nTiền xử lý dữ liệu Tải dữ liệu từ Hugging Face: https://huggingface.co/datasets/5CD-AI/Viet-Doc-VQA-II/tree/main/data Nhập thư viện cần thiết import os\rimport ast\rimport csv\rimport json\rimport numpy as np\rimport pandas as pd\rfrom sklearn.model_selection import train_test_split Đọc file parquet thành Dataframe df = pd.read_parquet(\u0026#39;train-00000-of-00034.parquet\u0026#39;, engine=\u0026#34;pyarrow\u0026#34;)\rdf[\u0026#39;conversations\u0026#39;] = df[\u0026#39;conversations\u0026#39;].apply(\rlambda x: json.dumps(x.tolist(), ensure_ascii=False) if isinstance(x, np.ndarray) else json.dumps(x, ensure_ascii=False)\r)\rdf = df.head(100) Chia dữ liệu thành 3 bộ train (90%), test (10%) # Chia tập train (90%) và tập test (10%)\rtrain_df, test_df = train_test_split(df, test_size=0.1)\rtrain_df.to_csv(\u0026#34;viet_vqa_train.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;)\rtest_df.to_csv(\u0026#34;viet_vqa_test.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;)\rdf_train = pd.read_csv(\u0026#39;viet_vqa_train.csv\u0026#39;)\rdf_test = pd.read_csv(\u0026#39;viet_vqa_test.csv\u0026#39;) -\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026raquo;\u0026gt;1 tấm hình chỗ này show console số lượng dữ liệu\nĐịnh dạng dữ liệu theo format AWS Bedrock Định dạng mẫu của AWS Bedrock item = {\r\u0026#34;schemaVersion\u0026#34;: \u0026#34;bedrock-conversation-2024\u0026#34;,\r\u0026#34;system\u0026#34;: [\r{\r\u0026#34;text\u0026#34;: (\r\u0026#34;You are an AI assistant specialized in Q\u0026amp;A based on Vietnamese images. \u0026#34;\r\u0026#34;You can analyze image content, recognize text (OCR), understand context, \u0026#34;\r\u0026#34;and answer questions based on extracted information. \u0026#34;\r\u0026#34;Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. \u0026#34;\r\u0026#34;Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. \u0026#34;\r\u0026#34;Concise Responses: Provide clear, precise, and natural Vietnamese responses. \u0026#34;\r\u0026#34;Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. \u0026#34;\r\u0026#34;Professional \u0026amp; Objective: Respond factually based on the image, avoiding assumptions beyond the given data.\u0026#34;\r)\r}\r],\r\u0026#34;messages\u0026#34;: [\r{\r\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;,\r\u0026#34;content\u0026#34;: [\r{\u0026#34;text\u0026#34;: \u0026#34;\u0026#34;},\r{\r\u0026#34;image\u0026#34;: {\r\u0026#34;format\u0026#34;: \u0026#34;png\u0026#34;,\r\u0026#34;source\u0026#34;: {\r\u0026#34;s3Location\u0026#34;: {\r\u0026#34;uri\u0026#34;: \u0026#34;s3://test-fineture-novalite/data-fineture/image_sample_1.jpg\u0026#34;,\r\u0026#34;bucketOwner\u0026#34;: \u0026#34;536*********\u0026#34;\r}\r}\r}\r}\r]\r},\r{\r\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;,\r\u0026#34;content\u0026#34;: [\r{\u0026#34;text\u0026#34;: \u0026#34;\u0026#34;}\r]\r}\r]\r} Hàm định dạng dữ liệu, thông điêp đầu tiên của role user sẽ chứa thêm hình ảnh, kết hợp với các thông điệp trong mẫu dữ liệu tạo ra 1 conversation. def create_jsonl_item(row):\rtry:\rconversations = row.get(\u0026#34;conversations\u0026#34;)\rjson_conversation = json.loads(conversations)\rfor item in json_conversation:\rif isinstance(item[\u0026#34;content\u0026#34;], str):\ritem[\u0026#34;content\u0026#34;] = [{\u0026#34;text\u0026#34;: item[\u0026#34;content\u0026#34;]}]\rmessage_id = row.get(\u0026#34;id\u0026#34;)\rif isinstance(conversations, str):\rconversations = json.loads(conversations)\rif not isinstance(conversations, list):\rraise ValueError(\u0026#34;Invalid JSON format in conversations column\u0026#34;)\rif len(json_conversation) \u0026gt; 0 and json_conversation[0][\u0026#34;role\u0026#34;] == \u0026#34;user\u0026#34;:\rimage_info = {\r\u0026#34;image\u0026#34;: {\r\u0026#34;format\u0026#34;: \u0026#34;png\u0026#34;,\r\u0026#34;source\u0026#34;: {\r\u0026#34;s3Location\u0026#34;: {\r\u0026#34;uri\u0026#34;: f\u0026#34;s3://data-vqa-fine-tune-nova/train/image_{message_id}.png\u0026#34;,\r\u0026#34;bucketOwner\u0026#34;: \u0026#34;536*********\u0026#34;\r}\r}\r}\r}\rcontent_user = json_conversation[0][\u0026#34;content\u0026#34;]\rcontent_user.append(image_info)\rjson_conversation[0][\u0026#34;content\u0026#34;] = content_user\rprint(json_conversation)\rreturn {\r\u0026#34;schemaVersion\u0026#34;: \u0026#34;bedrock-conversation-2024\u0026#34;,\r\u0026#34;system\u0026#34;: [\r{\r\u0026#34;text\u0026#34;: (\r\u0026#34;You are an AI assistant specialized in Q\u0026amp;A based on Vietnamese images. \u0026#34;\r\u0026#34;You can analyze image content, recognize text (OCR), understand context, \u0026#34;\r\u0026#34;and answer questions based on extracted information. \u0026#34;\r\u0026#34;Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. \u0026#34;\r\u0026#34;Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. \u0026#34;\r\u0026#34;Concise Responses: Provide clear, precise, and natural Vietnamese responses. \u0026#34;\r\u0026#34;Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. \u0026#34;\r\u0026#34;Professional \u0026amp; Objective: Respond factually based on the image, avoiding assumptions beyond the given data.\u0026#34;\r)\r}\r],\r\u0026#34;messages\u0026#34;: json_conversation\r}\rexcept Exception as e:\rprint(f\u0026#34;Lỗi khi xử lý conversations: {e}, row conversation: {conversations}\u0026#34;)\rreturn None Đọc dữ liệu train từ file viet_vqa_train.csv df_train = pd.read_csv(\u0026#39;viet_vqa_train.csv\u0026#39;)\rdf_train Chuyển đổi hình ảnh dạng bytes thành file png và lưu trong một folder để upload lên s3 bucket. output_folder = \u0026#39;train_images\u0026#39;\rif not os.path.exists(output_folder):\ros.makedirs(output_folder)\rfor idx, row in df_train.iterrows():\rtry:\rimage_bytes = eval(row[\u0026#39;image\u0026#39;])\rimage_data = image_bytes[\u0026#39;bytes\u0026#39;] if isinstance(image_bytes, dict) else image_bytes\rimg = Image.open(io.BytesIO(image_data))\rfile_path = os.path.join(output_folder, f\u0026#39;image_{idx}.png\u0026#39;)\rimg.save(file_path, format=\u0026#39;PNG\u0026#39;)\rprint(f\u0026#34;Đã lưu ảnh: {file_path}\u0026#34;)\rexcept Exception as e:\rprint(f\u0026#34;Lỗi khi xử lý ảnh ở dòng {idx}: {e}\u0026#34;) Apply cho cả Dataframe jsonl_data = df_train.apply(create_jsonl_item, axis=1).tolist() Lưu lại thành file jsonl jsonl_data = [item for item in jsonl_data if item is not None]\rwith open(\u0026#34;data_train_90.jsonl\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f:\rfor item in jsonl_data:\rjson.dump(item, f, ensure_ascii=False)\rf.write(\u0026#34;\\n\u0026#34;) Tương tự như cách làm của bộ dữ liệu train, ta sẽ áp dụng cho file viet_vqa_test.csv.\nUpload tất cả lên s3. Ta được cấu trúc bộ dữ liệu trên s3 như hình bên dưới. "
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-dataset/2.2-upload/",
	"title": "Upload dữ liệu",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/3-train/",
	"title": "Fine-tuning",
	"tags": [],
	"description": "",
	"content": "Các giới hạn Custom model bedrock Chọn region us-east-1 (N. Virginia)\nChọn mục Custom models (fine tuning, dist,\u0026hellip;)\nChọn Create Fine-tuning job Chọn mô hình muốn fine-tuning, ở đây mình chọn Nova Lite. Điền tên mô hình fine-tuning và tên job. Phần input data, ô đầu tiên các bạn chọn tới đường dẫn file train_jsonl. Hiện nay, với các bài toán fine-tuning, chúng ta cũng không cần thiết phải có dữ liệu val, tại vì\u0026hellip; Các siêu thông số huấn luyện mình chọn như hình bên dưới Chọn đường dẫn lưu mô hình đầu ra sau khi fine tune, chọn service role cấp quyền bedrock truy cập tới S3. Chọn Create Fine-tuning job\nNếu tất cả các format đều đúng và không có lỗi gì xảy ra. Bạn ra màn tab Jobs bên ngoài sẽ thấy Fine-tuning job đang trong quá trình In Progress. Thời gian phụ thuộc vào số lượng mẫu dữ liệu và epochs. Trường hợp của mình tầm 10 phút.\n"
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/4-evaluation/",
	"title": "Đánh giá mô hình",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/5-clean/",
	"title": "Dọn tài nguyên",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]