[
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-finetune/1-dataset/",
	"title": "Chuẩn bị dataset",
	"tags": [],
	"description": "",
	"content": "Tổng quan về bộ dữ liệu Bộ dữ liệu này là phần mở rộng của dự án Viet Document VAQ, được xây dựng từ 64.765 trang tài liệu giáo dục tiếng Việt 🇻🇳, bao gồm: sách bài tập, sách chuyên đề, giáo án từ các nhà xuất bản chính thống như Bộ Giáo dục \u0026amp; Đào tạo, Cánh Diều, Chân Trời Sáng Tạo, Kết Nối Tri Thức,\u0026hellip; phủ rộng tất cả các môn học từ lớp 1 đến lớp 12.\nMỗi trang tài liệu đã được xử lý và chú thích kỹ lưỡng bằng các kỹ thuật Visual Question Answering (VQA) tiên tiến, tạo nên một bộ dữ liệu có chất lượng cao và giàu thông tin.\nBộ dữ liệu bao gồm 388.277 cặp mô tả chi tiết và câu hỏi - trả lời theo ngữ cảnh, được tự động tạo ra bởi Gemini 1.5 Flash – mô hình AI hàng đầu của Google, đang dẫn đầu bảng xếp hạng WildVision Arena. Nhờ đó, đây là nguồn tài nguyên lý tưởng cho các mục tiêu nghiên cứu và ứng dụng giáo dục hiện đại.\nCác môn học bao gồm: Toán học 📐, Ngữ văn 📚, Tiếng Anh 🇬🇧, Vật lý ⚛️, Hóa học 🧪, Sinh học 🌱, Lịch sử 📜, Địa lý 🌍, Giáo dục công dân 🏫, Tin học 💻, Công nghệ 🛠️, Âm nhạc 🎵, Mỹ thuật 🎨, Thể dục ⚽,\u0026hellip;\nTiền xử lý dữ liệu Nhập thư viện cần thiết import json\rimport csv\rimport pandas as pd\rimport numpy as np Đọc file parquet thành Dataframe df = pd.read_parquet(\u0026#39;train-00000-of-00034.parquet\u0026#39;, engine=\u0026#34;pyarrow\u0026#34;)\rdf[\u0026#39;conversations\u0026#39;] = df[\u0026#39;conversations\u0026#39;].apply(\rlambda x: json.dumps(x.tolist(), ensure_ascii=False) if isinstance(x, np.ndarray) else json.dumps(x, ensure_ascii=False)\r) Chia dữ liệu thành 3 bộ train (80%), val (10%), test (10%) # Chia tập train (80%) và tập val_test (20%)\rtrain_df, val_test_df = train_test_split(df, test_size=0.2)\r# Chia tiếp val_test thành validation (10%) và test (10%)\rval_df, test_df = train_test_split(val_test_df, test_size=0.5)\rtrain_df.to_csv(\u0026#34;viet_vqa_train.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;)\rval_df.to_csv(\u0026#34;viet_vqa_val.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;)\rtest_df.to_csv(\u0026#34;viet_vqa_test.csv\u0026#34;, index=False, encoding=\u0026#39;utf-8\u0026#39;)\rdf_train = pd.read_csv(\u0026#39;viet_vqa_train.csv\u0026#39;)\rdf_val = pd.read_csv(\u0026#39;viet_vqa_val.csv\u0026#39;)\rdf_test = pd.read_csv(\u0026#39;viet_vqa_test.csv\u0026#39;) Định dạng dữ liệu theo format AWS Bedrock Định dạng mẫu của AWS Bedrock item = {\r\u0026#34;schemaVersion\u0026#34;: \u0026#34;bedrock-conversation-2024\u0026#34;,\r\u0026#34;system\u0026#34;: [\r{\r\u0026#34;text\u0026#34;: (\r\u0026#34;You are an AI assistant specialized in Q\u0026amp;A based on Vietnamese images. \u0026#34;\r\u0026#34;You can analyze image content, recognize text (OCR), understand context, \u0026#34;\r\u0026#34;and answer questions based on extracted information. \u0026#34;\r\u0026#34;Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. \u0026#34;\r\u0026#34;Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. \u0026#34;\r\u0026#34;Concise Responses: Provide clear, precise, and natural Vietnamese responses. \u0026#34;\r\u0026#34;Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. \u0026#34;\r\u0026#34;Professional \u0026amp; Objective: Respond factually based on the image, avoiding assumptions beyond the given data.\u0026#34;\r)\r}\r],\r\u0026#34;messages\u0026#34;: [\r{\r\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;,\r\u0026#34;content\u0026#34;: [\r{\u0026#34;text\u0026#34;: \u0026#34;\u0026#34;},\r{\r\u0026#34;image\u0026#34;: {\r\u0026#34;format\u0026#34;: \u0026#34;png\u0026#34;,\r\u0026#34;source\u0026#34;: {\r\u0026#34;s3Location\u0026#34;: {\r\u0026#34;uri\u0026#34;: \u0026#34;s3://test-fineture-novalite/data-fineture/image_sample_1.jpg\u0026#34;,\r\u0026#34;bucketOwner\u0026#34;: \u0026#34;590******512\u0026#34;\r}\r}\r}\r}\r]\r},\r{\r\u0026#34;role\u0026#34;: \u0026#34;assistant\u0026#34;,\r\u0026#34;content\u0026#34;: [\r{\u0026#34;text\u0026#34;: \u0026#34;\u0026#34;}\r]\r}\r]\r} Hàm định dạng dữ liệu def create_jsonl_item(row):\rtry:\rconversations = row.get(\u0026#34;conversations\u0026#34;)\rmessage_id = row.get(\u0026#34;id\u0026#34;)\rif isinstance(conversations, str):\rconversations = json.loads(conversations)\rif not isinstance(conversations, list):\rraise ValueError(\u0026#34;Invalid JSON format in conversations column\u0026#34;)\rif len(conversations) \u0026gt; 0 and conversations[0][\u0026#34;role\u0026#34;] == \u0026#34;user\u0026#34;:\roriginal_text = conversations[0][\u0026#34;content\u0026#34;]\rimage_info = {\r\u0026#34;image\u0026#34;: {\r\u0026#34;format\u0026#34;: \u0026#34;png\u0026#34;,\r\u0026#34;source\u0026#34;: {\r\u0026#34;s3Location\u0026#34;: {\r\u0026#34;uri\u0026#34;: f\u0026#34;s3://data-vqa-fine-tune-nova/train/image_{message_id}.png\u0026#34;,\r\u0026#34;bucketOwner\u0026#34;: \u0026#34;536697245883\u0026#34;\r}\r}\r}\r}\rconversations[0][\u0026#34;content\u0026#34;] = [\r{\u0026#34;text\u0026#34;: original_text},\rimage_info\r]\rreturn {\r\u0026#34;schemaVersion\u0026#34;: \u0026#34;bedrock-conversation-2024\u0026#34;,\r\u0026#34;system\u0026#34;: [\r{\r\u0026#34;text\u0026#34;: (\r\u0026#34;You are an AI assistant specialized in Q\u0026amp;A based on Vietnamese images. \u0026#34;\r\u0026#34;You can analyze image content, recognize text (OCR), understand context, \u0026#34;\r\u0026#34;and answer questions based on extracted information. \u0026#34;\r\u0026#34;Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. \u0026#34;\r\u0026#34;Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. \u0026#34;\r\u0026#34;Concise Responses: Provide clear, precise, and natural Vietnamese responses. \u0026#34;\r\u0026#34;Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. \u0026#34;\r\u0026#34;Professional \u0026amp; Objective: Respond factually based on the image, avoiding assumptions beyond the given data.\u0026#34;\r)\r}\r],\r\u0026#34;messages\u0026#34;: conversations\r}\rexcept Exception as e:\rprint(f\u0026#34;Lỗi khi xử lý conversations: {e}, row ID: {row[\u0026#39;id\u0026#39;]}, {conversations}\u0026#34;)\rreturn None # Trả về None nếu có lỗi Apply cho cả Dataframe jsonl_data = df_sample.apply(create_jsonl_item, axis=1).tolist() Lưu lại thành file jsonl jsonl_data = [item for item in jsonl_data if item is not None]\rwith open(\u0026#34;data_finetune_100.jsonl\u0026#34;, \u0026#34;w\u0026#34;, encoding=\u0026#34;utf-8\u0026#34;) as f:\rfor item in jsonl_data:\rjson.dump(item, f, ensure_ascii=False)\rf.write(\u0026#34;\\n\u0026#34;) Tương tự như cách làm của file jsonl train, ta sẽ áp dụng cho file jsonl của val và test.\n"
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/",
	"title": "Customizing Amazon Nova models",
	"tags": [],
	"description": "",
	"content": "Customizing Amazon Nova models Tổng quan Trong bối cảnh AI và Machine Learning ngày càng phát triển, việc tinh chỉnh fine-tuning các mô hình ngôn ngữ lớn (LLM) trở nên quan trọng để tối ưu hóa hiệu suất theo nhu cầu cụ thể. Dự án của chúng tôi tập trung vào việc tùy chỉnh các mô hình Amazon Nova thông qua kỹ thuật fine-tuning, nhằm nâng cao độ chính xác và tính phù hợp của mô hình với bài toán thực tế.\nAmazon Nova là một dòng mô hình AI tiên tiến do AWS phát triển, cung cấp khả năng xử lý ngôn ngữ tự nhiên mạnh mẽ, có thể được tinh chỉnh để phù hợp với các ứng dụng doanh nghiệp, chatbot, phân tích văn bản, và nhiều bài toán AI khác. Bằng cách sử dụng fine-tuning, chúng tôi có thể điều chỉnh Nova theo dữ liệu cụ thể của dự án, cải thiện độ chính xác và khả năng phản hồi của mô hình đối với các truy vấn đặc thù.\nTrong phần tiếp theo, chúng tôi sẽ trình bày chi tiết về quy trình fine-tuning, công nghệ được sử dụng, và các thách thức kỹ thuật gặp phải trong quá trình triển khai dự án.\nKiến trúc Quy trình triển khai: Chuẩn bị dataset -\u0026gt; \u0026hellip;\nNội dung chính Giới thiệu Fine-tuning VQA trên Nova "
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Khái Niệm Trong phần này, chúng tôi giới thiệu các khái niệm và kỹ thuật chính được sử dụng để tùy chỉnh mô hình Amazon Nova, bao gồm Fine-tuning, Distillation, và Continued Pre-training. Mỗi phương pháp đều có ưu điểm và phù hợp với các yêu cầu cụ thể khác nhau.\nFine-tuning Khái niệm: Fine-tuning là quá trình huấn luyện thêm một mô hình ngôn ngữ đã được huấn luyện trước đó (pre-trained) trên một tập dữ liệu nhỏ hơn, chuyên biệt cho một tác vụ cụ thể. Điều này giúp mô hình hiểu rõ hơn về ngữ cảnh cụ thể của lĩnh vực ứng dụng.\nHình minh họa: Ưu điểm:\nCải thiện hiệu suất trên các tác vụ chuyên biệt Không cần nhiều dữ liệu như huấn luyện từ đầu Nhanh chóng và tiết kiệm chi phí Nhược điểm:\nDễ bị overfitting nếu dữ liệu quá ít Có thể làm mất đi kiến thức tổng quát của mô hình (catastrophic forgetting) Use case thực tế:\nChatbot chăm sóc khách hàng được fine-tune trên dữ liệu hội thoại nội bộ của công ty để trả lời chính xác hơn. Hệ thống phân loại email spam được tinh chỉnh với dữ liệu từ tổ chức cụ thể để tăng độ chính xác. Ứng dụng nhận dạng thực thể trong văn bản y tế (Medical NER) được fine-tune từ mô hình gốc để xử lý hồ sơ bệnh án. Distillation Khái niệm: Distillation (chưng cất mô hình) là kỹ thuật chuyển giao tri thức từ một mô hình lớn, phức tạp (teacher) sang một mô hình nhỏ, nhẹ hơn (student), giúp giảm kích thước và tăng tốc độ suy luận.\nHình minh họa: Ưu điểm:\nGiảm kích thước mô hình và độ trễ Dễ triển khai trên thiết bị có tài nguyên hạn chế (mobile, edge) Nhược điểm:\nCó thể giảm hiệu suất so với mô hình gốc Cần thêm một bước huấn luyện phụ Use case thực tế:\nTạo phiên bản nhẹ của mô hình chatbot để triển khai trên thiết bị IoT trong nhà thông minh. Rút gọn mô hình phân tích cảm xúc để tích hợp vào hệ thống hỗ trợ khách hàng trên ứng dụng di động. Triển khai phiên bản student của mô hình kiểm tra đạo văn cho các trường đại học có tài nguyên hạn chế. Continued Pre-training Khái niệm: Continued pre-training là quá trình huấn luyện tiếp tục một mô hình ngôn ngữ đã được huấn luyện trước đó trên một tập dữ liệu lớn không có nhãn, chuyên biệt theo lĩnh vực trước khi thực hiện fine-tuning.\nHình minh họa: Ưu điểm:\nGiúp mô hình hấp thụ thêm kiến thức chuyên ngành Cải thiện khả năng tổng quát hoá khi fine-tune Nhược điểm:\nTốn nhiều tài nguyên tính toán Yêu cầu tập dữ liệu lớn và phù hợp với lĩnh vực Use case thực tế:\nTiền huấn luyện mô hình với hàng triệu bài báo khoa học trước khi fine-tune cho hệ thống trích xuất thông tin học thuật. Sử dụng dữ liệu từ các diễn đàn công nghệ để tiếp tục huấn luyện mô hình, sau đó tinh chỉnh cho trợ lý kỹ thuật. Huấn luyện tiếp mô hình trên tập tin tài chính doanh nghiệp để cải thiện hệ thống phân tích báo cáo tài chính. So sánh các kỹ thuật tùy chỉnh mô hình Tiêu chí Fine-tuning Distillation Continued Pre-training Dữ liệu đầu vào Có nhãn Có nhãn và mô hình teacher Không nhãn Mục tiêu chính Tùy chỉnh mô hình theo tác vụ cụ thể Nén mô hình, tăng tốc suy luận Mở rộng kiến thức chuyên ngành Yêu cầu tài nguyên Trung bình Thấp Cao Khả năng triển khai Dễ triển khai với mô hình có sẵn Phù hợp thiết bị giới hạn tài nguyên Yêu cầu pipeline huấn luyện phức tạp hơn Độ phức tạp Vừa phải Thấp đến trung bình Cao Nguy cơ overfitting Cao nếu ít dữ liệu Thấp Thấp Ưu điểm nổi bật Cá nhân hóa mạnh mẽ cho tác vụ cụ thể Nhẹ, nhanh, dễ triển khai Học sâu hơn theo lĩnh vực, tăng khả năng generalization Nhược điểm Có thể làm mất kiến thức tổng quát Hiệu suất kém hơn mô hình gốc Tốn tài nguyên, cần dữ liệu lớn Ví dụ ứng dụng Chatbot doanh nghiệp, phân loại văn bản Ứng dụng mobile, IoT, hệ thống nhúng Trích xuất thông tin chuyên ngành, phân tích tài chính Tổng kết Trong phần giới thiệu này, chúng tôi đã làm rõ ba phương pháp chính để tùy chỉnh mô hình Amazon Nova: Fine-tuning, Distillation và Continued Pre-training. Mỗi phương pháp có những điểm mạnh, điểm yếu và yêu cầu khác nhau, phục vụ những mục tiêu triển khai cụ thể:\nNếu cần mô hình phản hồi chính xác cho một tác vụ cụ thể, Fine-tuning là lựa chọn tối ưu. Nếu cần triển khai trên thiết bị tài nguyên thấp, Distillation là giải pháp phù hợp. Khi cần mô hình hiểu sâu hơn về ngữ cảnh ngành nghề, Continued Pre-training là hướng đi hiệu quả. Trong các phần tiếp theo, chúng tôi sẽ trình bày chi tiết cách áp dụng từng kỹ thuật vào quy trình huấn luyện mô hình Nova, cùng các công cụ và kiến trúc hỗ trợ.\n"
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-finetune/",
	"title": "Fine-tuning VQA trên Nova",
	"tags": [],
	"description": "",
	"content": "Nội Dung Chuẩn bị dataset S3 bucket Huấn luyện mô hình Kết quả thử nghiệm Xóa tài nguyên "
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-finetune/2-s3/",
	"title": "S3 bucket",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-finetune/3-train/",
	"title": "Huấn luyện mô hình",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-finetune/4-result/",
	"title": "Kết quả thử nghiệm",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/2-finetune/5-clean/",
	"title": "Xóa tài nguyên",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/3-distillation/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/4-pre-training/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://cloudmindshub.github.io/workshop/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]