+++
title = "Chu·∫©n b·ªã dataset"
date = 2025
weight = 2
chapter = false
pre = "<b>2. </b>"
+++


### T·ªïng quan v·ªÅ b·ªô d·ªØ li·ªáu

B·ªô d·ªØ li·ªáu n√†y l√† ph·∫ßn m·ªü r·ªông c·ªßa d·ª± √°n Viet-Doc VAQ, ƒë∆∞·ª£c x√¢y d·ª±ng t·ª´ 64.765 trang t√†i li·ªáu gi√°o d·ª•c ti·∫øng Vi·ªát üáªüá≥, bao g·ªìm: s√°ch b√†i t·∫≠p, s√°ch chuy√™n ƒë·ªÅ, gi√°o √°n t·ª´ c√°c nh√† xu·∫•t b·∫£n ch√≠nh th·ªëng nh∆∞ B·ªô Gi√°o d·ª•c & ƒê√†o t·∫°o, C√°nh Di·ªÅu, Ch√¢n Tr·ªùi S√°ng T·∫°o, K·∫øt N·ªëi Tri Th·ª©c,... ph·ªß r·ªông t·∫•t c·∫£ c√°c m√¥n h·ªçc t·ª´ l·ªõp 1 ƒë·∫øn l·ªõp 12.

M·ªói trang t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† ch√∫ th√≠ch k·ªπ l∆∞·ª°ng b·∫±ng c√°c k·ªπ thu·∫≠t Visual Question Answering (VQA), t·∫°o n√™n m·ªôt b·ªô d·ªØ li·ªáu c√≥ ch·∫•t l∆∞·ª£ng cao v√† gi√†u th√¥ng tin.

B·ªô d·ªØ li·ªáu bao g·ªìm 388.277 c·∫∑p m√¥ t·∫£ chi ti·∫øt v√† c√¢u h·ªèi - tr·∫£ l·ªùi theo ng·ªØ c·∫£nh, ƒë∆∞·ª£c t·ª± ƒë·ªông t·∫°o ra b·ªüi Gemini 1.5 Flash ‚Äì m√¥ h√¨nh AI h√†ng ƒë·∫ßu c·ªßa Google, ƒëang d·∫´n ƒë·∫ßu b·∫£ng x·∫øp h·∫°ng WildVision Arena. Nh·ªù ƒë√≥, ƒë√¢y l√† ngu·ªìn t√†i nguy√™n l√Ω t∆∞·ªüng cho c√°c m·ª•c ti√™u nghi√™n c·ª©u v√† ·ª©ng d·ª•ng gi√°o d·ª•c hi·ªán ƒë·∫°i.

C√°c m√¥n h·ªçc bao g·ªìm: To√°n h·ªçc üìê, Ng·ªØ vƒÉn üìö, Ti·∫øng Anh üá¨üáß, V·∫≠t l√Ω ‚öõÔ∏è, H√≥a h·ªçc üß™, Sinh h·ªçc üå±, L·ªãch s·ª≠ üìú, ƒê·ªãa l√Ω üåç, Gi√°o d·ª•c c√¥ng d√¢n üè´, Tin h·ªçc üíª, C√¥ng ngh·ªá üõ†Ô∏è, √Çm nh·∫°c üéµ, M·ªπ thu·∫≠t üé®, Th·ªÉ d·ª•c ‚öΩ,...

Ch·ªâ ƒë·ªÉ th·ª≠ nghi·ªám vi·ªác fine-tuning m√¥ h√¨nh tr√™n AWS Bedrock, trong workshop n√†y ch·ªâ d√πng 1 file parquet c·ªßa ƒë·ªÉ hu·∫•n luy·ªán.

### Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu

- T·∫£i d·ªØ li·ªáu t·ª´ Hugging Face: https://huggingface.co/datasets/5CD-AI/Viet-Doc-VQA-II/tree/main/data

![Architecture](/static/images/2-dataset/data-hf.png)

- Nh·∫≠p th∆∞ vi·ªán c·∫ßn thi·∫øt

```
import os
import ast
import json
import pandas as pd
```

- ƒê·ªçc file parquet th√†nh Dataframe

```
df = pd.read_parquet('train-00000-of-00034.parquet', engine="pyarrow")

df['conversations'] = df['conversations'].apply(
    lambda x: json.dumps(x.tolist(), ensure_ascii=False) if isinstance(x, np.ndarray) else json.dumps(x, ensure_ascii=False)
)
```

- Chia d·ªØ li·ªáu th√†nh 3 b·ªô train (80%), val (10%), test (10%)

```
# Chia t·∫≠p train (80%) v√† t·∫≠p val_test (20%)
train_df, val_test_df = train_test_split(df, test_size=0.2)

# Chia ti·∫øp val_test th√†nh validation (10%) v√† test (10%)
val_df, test_df = train_test_split(val_test_df, test_size=0.5)

train_df.to_csv("viet_vqa_train.csv", index=False, encoding='utf-8')
val_df.to_csv("viet_vqa_val.csv", index=False, encoding='utf-8')
test_df.to_csv("viet_vqa_test.csv", index=False, encoding='utf-8')

df_train = pd.read_csv('viet_vqa_train.csv')
df_val = pd.read_csv('viet_vqa_val.csv')
df_test = pd.read_csv('viet_vqa_test.csv')
```


### ƒê·ªãnh d·∫°ng d·ªØ li·ªáu theo format AWS Bedrock

- ƒê·ªãnh d·∫°ng m·∫´u c·ªßa AWS Bedrock
```
item = {
    "schemaVersion": "bedrock-conversation-2024",
    "system": [
        {
            "text": (
                "You are an AI assistant specialized in Q&A based on Vietnamese images. "
                "You can analyze image content, recognize text (OCR), understand context, "
                "and answer questions based on extracted information. "
                "Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. "
                "Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. "
                "Concise Responses: Provide clear, precise, and natural Vietnamese responses. "
                "Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. "
                "Professional & Objective: Respond factually based on the image, avoiding assumptions beyond the given data."
            )
        }
    ],
    "messages": [
        {
            "role": "user",
            "content": [
                {"text": ""},
                {
                    "image": {
                        "format": "png",
                        "source": {
                            "s3Location": {
                                "uri": "s3://test-fineture-novalite/data-fineture/image_sample_1.jpg",
                                "bucketOwner": "590******512"
                            }
                        }
                    }
                }
            ]
        },
        {
            "role": "assistant",
            "content": [
                {"text": ""}
            ]
        }
    ]
}
```

- H√†m ƒë·ªãnh d·∫°ng d·ªØ li·ªáu
```
def create_jsonl_item(row):
    try:
        conversations = row.get("conversations")
        message_id = row.get("id")
        if isinstance(conversations, str):
            conversations = json.loads(conversations)
            
        if not isinstance(conversations, list):
            raise ValueError("Invalid JSON format in conversations column")

        if len(conversations) > 0 and conversations[0]["role"] == "user":
            original_text = conversations[0]["content"]
            image_info = {
                "image": {
                    "format": "png",
                    "source": {
                        "s3Location": {
                            "uri": f"s3://data-vqa-fine-tune-nova/train/image_{message_id}.png",
                            "bucketOwner": "536697245883"
                        }
                    }
                }
            }
            conversations[0]["content"] = [
                {"text": original_text},
                image_info
            ]

        return {
            "schemaVersion": "bedrock-conversation-2024",
            "system": [
                {
                    "text": (
                        "You are an AI assistant specialized in Q&A based on Vietnamese images. "
                        "You can analyze image content, recognize text (OCR), understand context, "
                        "and answer questions based on extracted information. "
                        "Behavior Guidelines Text Recognition: Use OCR to extract textual content from images. "
                        "Context Understanding: Identify the meaning of the extracted text and image to provide accurate answers. "
                        "Concise Responses: Provide clear, precise, and natural Vietnamese responses. "
                        "Image Analysis Support: If a question requires more than text extraction, analyze the visual content as well. "
                        "Professional & Objective: Respond factually based on the image, avoiding assumptions beyond the given data."
                    )
                }
            ],
            "messages": conversations
        }
    except Exception as e:
        print(f"L·ªói khi x·ª≠ l√Ω conversations: {e}, row ID: {row['id']}, {conversations}")
        return None  # Tr·∫£ v·ªÅ None n·∫øu c√≥ l·ªói
```

- Apply cho c·∫£ Dataframe
```
jsonl_data = df_sample.apply(create_jsonl_item, axis=1).tolist()
```

- L∆∞u l·∫°i th√†nh file jsonl
```
jsonl_data = [item for item in jsonl_data if item is not None]

with open("data_finetune_100.jsonl", "w", encoding="utf-8") as f:
    for item in jsonl_data:
        json.dump(item, f, ensure_ascii=False)
        f.write("\n")
```

{{% notice note %}}
T∆∞∆°ng t·ª± nh∆∞ c√°ch l√†m c·ªßa file jsonl train, ta s·∫Ω √°p d·ª•ng cho file jsonl c·ªßa val v√† test.
{{% /notice %}}